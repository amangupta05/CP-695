{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JK7FRujREvy6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1JC9ut56Ez_4"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"RELIANCE.NS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cjXqVqJ4Ez9i"
   },
   "outputs": [],
   "source": [
    "# Drop any missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Convert the 'Date' column to a datetime object\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort the DataFrame by date\n",
    "df.sort_values('Date', inplace=True)\n",
    "\n",
    "# Select the 'Close' column as the target variable\n",
    "target_col = 'Close'\n",
    "\n",
    "# Define the sliding window size\n",
    "window_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Pa-U1c9UEz7O"
   },
   "outputs": [],
   "source": [
    "# Normalize the data using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[[target_col]] = scaler.fit_transform(df[[target_col]])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(0.8 * len(df))\n",
    "train_df = df[:train_size].reset_index(drop=True)\n",
    "test_df = df[train_size:].reset_index(drop=True)\n",
    "\n",
    "# Create sliding windows of data for the training set\n",
    "train_X, train_y = [], []\n",
    "for i in range(window_size, len(train_df)):\n",
    "    train_X.append(train_df[target_col].iloc[i-window_size:i])\n",
    "    train_y.append(train_df[target_col].iloc[i])\n",
    "train_X, train_y = np.array(train_X), np.array(train_y)\n",
    "\n",
    "# Create sliding windows of data for the testing set\n",
    "test_X, test_y = [], []\n",
    "for i in range(window_size, len(test_df)):\n",
    "    test_X.append(test_df[target_col].iloc[i-window_size:i])\n",
    "    test_y.append(test_df[target_col].iloc[i])\n",
    "test_X, test_y = np.array(test_X), np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VQttUIX9Ez4l"
   },
   "outputs": [],
   "source": [
    "# Reshape the data to fit the LSTM input shape\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))\n",
    "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GCC_5Sq1Ez13"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Abrnex_-Ezy7"
   },
   "outputs": [],
   "source": [
    "# Define a function to build the LSTM model\n",
    "def build_lstm(look_back=30, units=32, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(look_back, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0H8FbgkcEzwZ",
    "outputId": "a457b12b-61d9-4b5a-e0c3-91dafd7f2a8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6h/p8nwbyjj3sv4vz65r6gg_vdm0000gn/T/ipykernel_83780/3455719602.py:2: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  regressor = KerasRegressor(build_fn=build_lstm, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# Create a KerasRegressor with the build_lstm function\n",
    "regressor = KerasRegressor(build_fn=build_lstm, verbose=0)\n",
    "\n",
    "# Define the hyperparameters to test using GridSearchCV\n",
    "params = {\n",
    "    'look_back': [30, 60, 90],\n",
    "    'units': [32, 64, 128],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [10, 20, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VycvJVE1EzrZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 16:05:21.013903: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# Create a GridSearchCV object with the KerasRegressor and hyperparameters\n",
    "grid_search = GridSearchCV(estimator=regressor, param_grid=params, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6cPJaGnEzor"
   },
   "outputs": [],
   "source": [
    "# Use the best hyperparameters to create the final model\n",
    "best_params = grid_search.best_params_\n",
    "model = build_lstm(look_back=best_params['look_back'], units=best_params['units'], optimizer=best_params['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQAXMJzrEzmR"
   },
   "outputs": [],
   "source": [
    "# Train the model on the training data\n",
    "history = model.fit(train_X, train_y, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=2, validation_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ByDkYTlnEzjw"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions on the testing data with the trained model\n",
    "y_pred = model.predict(test_X)\n",
    "\n",
    "# Inverse transform the normalized data\n",
    "y_pred = scaler.inverse_transform(y_pred)\n",
    "test_y = scaler.inverse_transform(test_y)\n",
    "\n",
    "# Plot the actual and predicted values\n",
    "plt.plot(test_y, label='Actual')\n",
    "plt.plot(y_pred, label='Predicted')\n",
    "\n",
    "plt.xlabel('Time (days)')\n",
    "plt.ylabel('Stock Price ($)')\n",
    "plt.title('Actual vs Predicted Stock Prices')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_I-Z6-VoEzhI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
