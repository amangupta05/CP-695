{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "B4xn8Bi6CwSs"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense, Dropout\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('AAPL.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\u001b[0m\u001b[31m\r\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSLNf6FlCwP6"
   },
   "outputs": [],
   "source": [
    "num_features = data.shape[1]\n",
    "\n",
    "# Create a copy of the DataFrame without the date column\n",
    "data_numeric = data.drop('Date', axis=1)\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "data_norm = scaler.fit_transform(data_numeric)\n",
    "\n",
    "# Add the date column back to the normalized data\n",
    "data_norm = np.concatenate((data[['Date']].values, data_norm), axis=1)\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_size = int(len(data_norm) * 0.8)\n",
    "train_data = data_norm[:train_size, :]\n",
    "test_data = data_norm[train_size:, :]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o46k0pslCwM8"
   },
   "outputs": [],
   "source": [
    "# Generate data with sliding windows\n",
    "def create_dataset(data, num_timesteps):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(num_timesteps, len(data)):\n",
    "        X.append(data[i-num_timesteps:i, :])\n",
    "        y.append(data[i, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define the hyperparameters search space\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=256, step=32), \n",
    "                   input_shape=(num_timesteps, num_features), \n",
    "                   return_sequences=True))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=128, step=32), \n",
    "                   return_sequences=True))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=16, max_value=64, step=16)))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', \n",
    "                              values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jEtcx-VsByjs",
    "outputId": "ff17cc46-d444-4a74-e6fa-039c74e785f1"
   },
   "outputs": [],
   "source": [
    "# Perform hyperparameter tuning\n",
    "num_timesteps = 10\n",
    "\n",
    "tuner = RandomSearch(build_model, objective='val_loss', max_trials=10, executions_per_trial=3)\n",
    "X_train, y_train = create_dataset(train_data, num_timesteps)\n",
    "X_test, y_test = create_dataset(test_data, num_timesteps)\n",
    "tuner.search(X_train, y_train, epochs=64, batch_size=100, validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "vdfOyDCha1HH",
    "outputId": "5adcd3a9-c171-4966-f9bc-57764fe70321"
   },
   "outputs": [],
   "source": [
    "# Evaluate best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, verbose=2)\n",
    "train_score = best_model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train score:', train_score)\n",
    "test_score = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', test_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UQKTrQpa3Pm"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "train_predictions = best_model.predict(X_train)\n",
    "test_predictions = best_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OP4BxHUba3Nb"
   },
   "outputs": [],
   "source": [
    "# Inverse normalization of predictions\n",
    "train_predictions = scaler.inverse_transform(train_predictions)\n",
    "y_train = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "test_predictions = scaler.inverse_transform(test_predictions)\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "teV1-aEWa3Kj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EqDcPD3ua3Hw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
