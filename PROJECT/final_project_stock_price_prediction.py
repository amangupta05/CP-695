# -*- coding: utf-8 -*-
"""Final Project Stock Price Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13CG5CAkz7Hu55y0Lquz5ggezx7yjTZG0
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dropout, Dense

# Load the data
data = pd.read_csv('/content/KO (1).csv', date_parser=True)
data = data.sort_values('Date')

data = data.sort_values('Date')

# Define the number of time steps
time_steps = 60

# Split the data into training and test sets
train_data = data[:int(len(data) * 0.8)]
test_data = data[int(len(data) * 0.8) - time_steps:]

# Normalize the data
scaler = MinMaxScaler()
train_scaled = scaler.fit_transform(train_data[['Close']])
test_scaled = scaler.transform(test_data[['Close']])

# Prepare the training data
X_train = []
y_train = []
for i in range(time_steps, len(train_scaled)):
    X_train.append(train_scaled[i - time_steps:i, 0])
    y_train.append(train_scaled[i, 0])
X_train, y_train = np.array(X_train), np.array(y_train)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

# Prepare the test data
X_test = []
y_test = []
for i in range(time_steps, len(test_scaled)):
    X_test.append(test_scaled[i - time_steps:i, 0])
    y_test.append(test_scaled[i, 0])
X_test, y_test = np.array(X_test), np.array(y_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# Create the LSTM model
model = Sequential()
model.add(LSTM(units=128, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(Dropout(0.2))
model.add(LSTM(units=64, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=64))
model.add(Dropout(0.2))
model.add(Dense(units=1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X_train, y_train, epochs=100, batch_size=32)

# Make predictions
y_pred = scaler.inverse_transform(model.predict(X_test))

# Evaluate the model
score = model.evaluate(X_test, y_test)

# Visualize the results
import matplotlib.pyplot as plt
plt.plot(test_data['Date'].iloc[time_steps:], test_data['Close'].iloc[time_steps:], color='blue', label='Actual Price')
plt.plot(test_data['Date'].iloc[time_steps:], y_pred, color='red', label='Predicted Price')
plt.xticks(np.arange(0, len(test_data)-time_steps, step=50), test_data['Date'].iloc[time_steps::50])
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dropout, Dense
from scipy.stats import pearsonr

# Load the data
data = pd.read_csv('AAPL.csv', date_parser=True)

# EDA
# Print the first few rows of the data
print(data.head())

# Check for missing values
print(data.isna().sum())

# Visualize the closing prices over time
plt.plot(data['Date'], data['Close'])
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('Closing Prices Over Time')
plt.show()

# Compute the correlation matrix
corr = data.corr()

# Visualize the correlation matrix as a heatmap
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# Create a new DataFrame to store the predictions
predictions = test_data.iloc[time_steps:].copy()
predictions['Predicted'] = y_pred.reshape(-1)

# Visualize the actual and predicted prices
plt.plot(predictions['Date'], predictions['Close'], color='blue', label='Actual Price')
plt.plot(predictions['Date'], predictions['Predicted'], color='red', label='Predicted Price')
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('Actual vs. Predicted Prices')
plt.legend()
plt.show()



